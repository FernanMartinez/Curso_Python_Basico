{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 12. Pandas\n",
    "<img  src= \"img/pandas1.jpeg\" style=\"width:500px; height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas é uma das bibliotecas mais utilizadas em Python para manipulação e análise de dados. Esta biblioteca é de código aberto, escrita em Numpy e oferece estruturas e operações para manipulação de tabelas numéricas e séries temporais.\n",
    "\n",
    "Os principais destaques são:\n",
    "- Possui dois tipos de objetos `pandas.core.frame.DataFrame` e `pandas.core.series.Series` com indexação integrada;\n",
    "- Facilita a leitura, escrita e modificação de arquivos com diferentes formatos, entre os quais se destaca .csv, .txt, .xlsx, SQL, HDF5 (Hierarchical Data Format version 5) dentre outros;\n",
    "- Permite tabelas com diferentes niveis de indexação;\n",
    "- Permite agrupamento de dados por categorias;\n",
    "- Realiza mesclagem e junção de conjuntos de dados com alto desempenho;\n",
    "- Altamente otimizado com códigos escritos em Cython e C;\n",
    "- Pandas é amplamente utilizado em ambientes acadêmicos e comerciais, incluindo finanças, neurociência, economia, estatística, publicidade, análise da web e muito mais.\n",
    "---\n",
    " \n",
    "  <font size=\"6\"> Os tópicos que vamos abordar nesta série de conversas são:</font>\n",
    "\n",
    "- [X] Instalação de pandas;\n",
    "- [x] Importando pandas;\n",
    "- [x] Series;\n",
    "- [x] DataFrame e manipulação;\n",
    " - [X] Criação de DataFrame;\n",
    " - [X] Extraindo informação por colunas. CUIDADO COM NOTAÇÃO SQL;\n",
    " - [X] Extraindo utilizando função loc;\n",
    " - [X] Extraindo utilizando função iloc;\n",
    " - [X] Adicionando novas colunas;\n",
    " - [X] Adicionando novas filas (função append);\n",
    " - [X] Eliminando colunas ou filas.\n",
    "- [X] Operadores de comparação e seleção condicional;\n",
    "- [X] Dados ausentes;\n",
    " - [X] Dropna\n",
    " - [X] filna\n",
    " - [X] replace\n",
    "- [X] Groupby, aggregate e apply\n",
    "- [ ] Juntando diffenrentes `DataFrame` \n",
    " - [ ] `concat`\n",
    " - [ ] `merge`\n",
    " - [ ] `join`\n",
    "- [ ] Operações\n",
    " - [ ] unique\n",
    " - [ ] nunique\n",
    " - [ ] value_counts\n",
    " - [ ] del ( )\n",
    " - [ ] columns\n",
    " - [ ] index\n",
    " - [ ] sort_values\n",
    " - [ ] pivol\n",
    "- [ ] Importando e exportando dados.\n",
    " - [ ] csv\n",
    " - [ ] excell\n",
    " - [ ] html\n",
    "- Aplicação\n",
    "---\n",
    "<font size=\"5\"> Recomento visitar o site oficial do projeto [Pandas](https://pandas.pydata.org/) para conhecer mais um pouco desta biblioteca.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Intalação do pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Para instalar pandas no nosso computador podemos utilizar o condas ou o pip.\n",
    "```python\n",
    "conda install pandas\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## importando pandas e numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:53:02.002384Z",
     "start_time": "2020-09-30T11:53:01.677863Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Series\n",
    "O conceito principal de uma [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html) em Pandas e trabalhar com vetores a partir do indice ou labels. A sintaxe para definir uma Series é:\n",
    "```python\n",
    " pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:29:23.053007Z",
     "start_time": "2020-09-30T11:29:23.041497Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definindo algumas variaveis que vamos utilizar\n",
    "valores  = np.random.randn(1, 10).reshape(10,)\n",
    "index_row = \"A B C D E F G H I J\".split(\" \")\n",
    "d = {key: value for key, value in zip(index_row, valores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:29:24.729481Z",
     "start_time": "2020-09-30T11:29:24.717266Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando uma Series passando somente os valores\n",
    "pd.Series(valores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:29:25.995099Z",
     "start_time": "2020-09-30T11:29:25.985580Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando uma Series passando data e index\n",
    "pd.Series(data=valores, index=index_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:29:34.957499Z",
     "start_time": "2020-09-30T11:29:34.938334Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Observemos que pomodes criar uma Series passando qualquer tipo de dados\n",
    "pd.Series(index=valores, data=index_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:29:37.519833Z",
     "start_time": "2020-09-30T11:29:37.513754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Observemos que uma Series se comporta muito semelhante ao dicionário dado que ela trabalhar com chave: valor,\n",
    "# portanto podemos criar uma Seires passando um dicionário\n",
    "pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Mas qual é a vantagem de utilizar uma Series em relação ao arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:29:39.849627Z",
     "start_time": "2020-09-30T11:29:39.793243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series_1 = pd.Series(data=[5, 10, 20, 30, 8], index=\"A B C D J\".split(\" \"))\n",
    "series_2 = pd.Series(data=[20, 15, 15, 5, 25], index=\"A B K D C\".split(\" \"))\n",
    "print(series_1)\n",
    "print(series_2)\n",
    "print(series_1 + series_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame e manipulação\n",
    "O objeto principal de Pandas é o [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), este objeto se aproxima ao que conhecemos como planilha de excell (somente em aparência). Para definir um DataFrame utilizamos a seguinte sintaxe:\n",
    "```python\n",
    "pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
    "```\n",
    "Neste caso os argumentos mais relevantes são `data`, `index` e `columns`, porém o único argumento obrigatório é o `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Criação de DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:01.363851Z",
     "start_time": "2020-09-30T11:30:01.356164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = np.arange(1, 17).reshape((4,4))\n",
    "index = \"Row_1 Row_2 Row_3 Row_4\".split(\" \")\n",
    "col = \"Col_1 Col_2 Col_3 Col_4\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:02.764530Z",
     "start_time": "2020-09-30T11:30:02.752637Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:04.482636Z",
     "start_time": "2020-09-30T11:30:04.469070Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definindo um DataFrame passando data\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:06.511438Z",
     "start_time": "2020-09-30T11:30:06.465713Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definindo um DataFrame passando data e index\n",
    "pd.DataFrame(data, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:08.642728Z",
     "start_time": "2020-09-30T11:30:08.601539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Definindo um DataFrame passando todos data, index e columns\n",
    "data_frame = pd.DataFrame(data, index, col)\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extraindo informação por colunas. *CUIDADO COM NOTAÇÃO SQL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:16.495910Z",
     "start_time": "2020-09-30T11:30:16.487811Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extraindo informação da columna Col_4\n",
    "data_frame[\"Col_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:18.107527Z",
     "start_time": "2020-09-30T11:30:18.093134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Podemos utilizar a notação de ponto e o nome da columna, porém esta forma não é recomendada\n",
    "data_frame.Col_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extraindo utilizando função loc\n",
    "A propriedade [`loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) permite obter os dados de um DataFrame a partir dos labels das filas e das coluna. A sintaxe para aplicar esta propriedade é:\n",
    "```python\n",
    "DataFrame.loc[]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:23.895586Z",
     "start_time": "2020-09-30T11:30:23.884266Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Podemos utilizar a função loc para extrair informação utilizando o índice da fila e o nome da coluna\n",
    "data_frame.loc[\"Row_1\", \"Col_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:25.618300Z",
     "start_time": "2020-09-30T11:30:25.604393Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Para extrair diferentes colunas ou fila passamos uma lista com os nomes das colunas e filas\n",
    "data_frame.loc[[\"Row_1\", \"Row_4\"], [\"Col_1\", \"Col_4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:26.963410Z",
     "start_time": "2020-09-30T11:30:26.948437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Também podemos utilizar a função loc para extrair filas\n",
    "data_frame.loc[\"Row_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T20:36:30.990759Z",
     "start_time": "2020-09-13T20:36:30.984811Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Extraindo utilizando função iloc\n",
    "Existe outra forma de extrair os valores de um DataFrame utilizando a notação aprendida em Numpy, para isso utilizamos a propriedade [`iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html):\n",
    "```python\n",
    "DataFrame.iloc[]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:31.847346Z",
     "start_time": "2020-09-30T11:30:31.832540Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:33.446008Z",
     "start_time": "2020-09-30T11:30:33.435187Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame.iloc[ [0, -1], [0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:35.130919Z",
     "start_time": "2020-09-30T11:30:35.122105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:38.033585Z",
     "start_time": "2020-09-30T11:30:37.985421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame.iloc[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adicionando novas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:44.319897Z",
     "start_time": "2020-09-30T11:30:44.290805Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame[\"Col_nova\"] = data_frame.iloc[:, -1] + data_frame.iloc[:, 0]\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:46.005292Z",
     "start_time": "2020-09-30T11:30:45.965711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame[\"Col_nova_2\"]  = 2\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:47.800617Z",
     "start_time": "2020-09-30T11:30:47.782333Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adicionando novas filas (função append)\n",
    "Para adicionar uma nova fila utilizamos a função [append()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html), essa função adiciona uma nova (ou novas) fila(s) no final do DataFrame. A sintaxe utilizada para isso é:\n",
    "```python\n",
    "DataFrame.append(other, ignore_index=False, verify_integrity=False, sort=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:57.497958Z",
     "start_time": "2020-09-30T11:30:57.492707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.array([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:30:59.269871Z",
     "start_time": "2020-09-30T11:30:59.200039Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame2 = pd.DataFrame([[1,2,3,4]], columns=col)\n",
    "data_frame.append(data_frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:04.490961Z",
     "start_time": "2020-09-30T11:31:04.457080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame.append(data_frame*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Eliminando colunas ou filas\n",
    "Para eliminar colunas ou filas de um DataFrame utilizamos a função [`drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html). Neste caso se deve passar o indice da fila que será eliminada ou o label da coluna. Além disso, deve-se especificar o `axis` o qual é 0 para filas e 1 para columnas. A sintaxe utilizada é:\n",
    "\n",
    "```python\n",
    "DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:11.298151Z",
     "start_time": "2020-09-30T11:31:11.265853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:12.966919Z",
     "start_time": "2020-09-30T11:31:12.947927Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Eliminando a primeira fila\n",
    "data_frame.drop(\"Row_1\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:14.646699Z",
     "start_time": "2020-09-30T11:31:14.618109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Eliminando varias filas \n",
    "data_frame.drop([\"Row_1\", \"Row_3\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:16.435372Z",
     "start_time": "2020-09-30T11:31:16.421772Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Eliminando a primeira coluna\n",
    "data_frame.drop(\"Col_1\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:18.516900Z",
     "start_time": "2020-09-30T11:31:18.504128Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:20.459527Z",
     "start_time": "2020-09-30T11:31:20.450194Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Eliminando a varias colunas coluna\n",
    "data_frame.drop([\"Col_1\", \"Col_4\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:22.418361Z",
     "start_time": "2020-09-30T11:31:22.395524Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame\n",
    "# é interessante o fato de não modificar o data_frame original?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operadores de comparação e seleção condicional\n",
    "Da mesma forma que é possível aplicar operadores de comparação em arrays, com pandas podemos aplicar os mesmos operadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:30.960156Z",
     "start_time": "2020-09-30T11:31:30.928146Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando dados para trabalhar\n",
    "np.random.seed(100)\n",
    "data2 = np.random.randint(-10, 10, (5,5))\n",
    "col2 = [f\"Col_{i}\" for i in range(1, 6)]\n",
    "row2 = [f\"Row_{i}\" for i in range(1, 6)]\n",
    "data_frame2 = pd.DataFrame(data2, row2, col2)\n",
    "data_frame2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:32.728370Z",
     "start_time": "2020-09-30T11:31:32.710363Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame2 > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:34.676929Z",
     "start_time": "2020-09-30T11:31:34.649730Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Podemos atribuir esse teste de comparação a uma variável e utiliza-o para realizar seleção\n",
    "comp = data_frame2 > 0\n",
    "data_frame2[comp] \n",
    "# data_frame2[data_frame2 > 0] \n",
    "data_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:36.631367Z",
     "start_time": "2020-09-30T11:31:36.619567Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aplicando uma comparação numa serie\n",
    "comp = data_frame2[\"Col_5\"] > 0\n",
    "data_frame2[comp][\"Col_1\"]\n",
    "data_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:39.193686Z",
     "start_time": "2020-09-30T11:31:39.182363Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aplicando comparações multiples\n",
    "comp1 = data_frame2[\"Col_5\"] >= 2 #(Row_1, Row_2 e Row_4)\n",
    "comp2 = data_frame2[\"Col_3\"] < -1 # (Row_1, Row_2)\n",
    "data_frame2[comp2 & comp1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:40.930964Z",
     "start_time": "2020-09-30T11:31:40.900472Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As tres linhas anteriores são equivalentes a:\n",
    "data_frame2[(data_frame2[\"Col_5\"] >= 2) & (data_frame2[\"Col_3\"] < -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:31:42.786914Z",
     "start_time": "2020-09-30T11:31:42.779019Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados ausentes\n",
    "Quando trabalhamos com dados provenientes de fontes externas (como base de dados, dados de sensores, etc), pode acontecer que existam dados com valores \"inapropriados\" ou valores ausentes. Nesse caso a biblioteca Pandas ajuda a processar esses valores.\n",
    "\n",
    "Cabe destacar que o conceito de dado \"inapropriado\" varia de cenário para cenário e aforma de tratar esses dados pode varia. Porém, Pandas possui uma diversa variedade de funções e metódos que podem ser utilizados para essa finalidade.\n",
    "\n",
    "Recomendo a leitura de [Working with missing data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html). Nesta leitura a empresa desenvolvedora da biblioteca Pandas apresenta varias formas de processar dados ausentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:53:13.990636Z",
     "start_time": "2020-09-30T11:53:13.927581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_1</th>\n",
       "      <th>Col_2</th>\n",
       "      <th>Col_3</th>\n",
       "      <th>Col_4</th>\n",
       "      <th>Col_5</th>\n",
       "      <th>Col_6</th>\n",
       "      <th>Col_7</th>\n",
       "      <th>Col_8</th>\n",
       "      <th>Col_9</th>\n",
       "      <th>Col_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Row_1</th>\n",
       "      <td>-2</td>\n",
       "      <td>-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_2</th>\n",
       "      <td>-8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_3</th>\n",
       "      <td>-6</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>-6</td>\n",
       "      <td>-6</td>\n",
       "      <td>-7</td>\n",
       "      <td>-3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>-8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-10</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>-2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_7</th>\n",
       "      <td>-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_8</th>\n",
       "      <td>-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_9</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-8</td>\n",
       "      <td>9</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row_10</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Col_1 Col_2 Col_3 Col_4 Col_5 Col_6 Col_7 Col_8 Col_9 Col_10\n",
       "Row_1     -2    -7   NaN     5     6     0    -8    -8    -8      4\n",
       "Row_2     -8     7     6   NaN    -6     1     6    -1    -8    NaN\n",
       "Row_3     -6    -9     3     9    -6    -6    -7    -3     7      5\n",
       "Row_4    NaN   NaN   NaN     6    -8   NaN     9    -8     4      7\n",
       "Row_5      6     5    -3     3   NaN     2     8   -10    -8      0\n",
       "Row_6      7   NaN     3     0   NaN   NaN     8    -2     9      4\n",
       "Row_7    -10   NaN     2     0   NaN    -4   NaN     5     0    NaN\n",
       "Row_8     -7   NaN     6     1    -6    -5    -3    -4    -8      0\n",
       "Row_9      8   NaN     2    -9    -4     0   -10    -8     9     -6\n",
       "Row_10     8   NaN   NaN    -1   NaN     6    -4    -5   NaN    NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando data frame com valores nan\n",
    "np.random.seed(100)\n",
    "n = 10\n",
    "data2 = np.random.randint(-10, 10, (n, n)).astype(object)\n",
    "col2 = [f\"Col_{i}\" for i in range(1, n + 1)]\n",
    "row2 = [f\"Row_{i}\" for i in range(1, n + 1)]\n",
    "for r in range(n):\n",
    "    for c in range(n):\n",
    "        if np.random.random() < 0.25:\n",
    "            data2[r, c] = np.nan\n",
    "data_frame_nan = pd.DataFrame(data2, row2, col2)\n",
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:56:12.824957Z",
     "start_time": "2020-09-14T16:56:12.799162Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Dropna\n",
    "\n",
    "Para excluir valores faltantes `NaN` utilizamos a função [`dropna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html). Os argumentos necessarios para esta função são:\n",
    "\n",
    "```python\n",
    "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:31.247369Z",
     "start_time": "2020-09-30T11:32:31.215514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Elimiando os valores NaN, observemos que o resultado é somente Row_3\n",
    "# Neste caso definimos axis=0, o que indica que caso alguma fila tenha pelo menos um Nan, a fila será excluida\n",
    "data_frame_nan.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:33.143636Z",
     "start_time": "2020-09-30T11:32:33.125768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Elimiando os valores NaN, observemos que o resultado é somente Col_8\n",
    "# Neste caso definimos axis=0, o que indica que caso alguma fila tenha pelo menos um Nan, a fila será excluida\n",
    "data_frame_nan.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:35.100436Z",
     "start_time": "2020-09-30T11:32:35.046828Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Também podemos definir a quantidade de valores no Nan que vamos aceitar. Por tanto se queremos aceitar\n",
    "# pelo menos um NaN devemos de passar `thresh=9`\n",
    "data_frame_nan.dropna(axis=1,thresh=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:37.452048Z",
     "start_time": "2020-09-30T11:32:37.402817Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Observemos que a tabela original não foi modificada.\n",
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:39.182867Z",
     "start_time": "2020-09-30T11:32:39.125107Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Se queremos modificar o arquivo original devemos passar `inplace=True`\n",
    "data_frame_nan.dropna(axis=1,thresh=7, inplace=True)\n",
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### fillna\n",
    "Outra forma de processar os dados faltantes é utilizando a função [`fillna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) a qual permite substituir o valor faltante por outro valor.\n",
    "```python\n",
    "DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:45.356638Z",
     "start_time": "2020-09-30T11:32:45.268772Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Criando data frame com valores nan\n",
    "np.random.seed(100)\n",
    "n = 10\n",
    "data2 = np.random.randint(25, 37, (n, n)).astype(object)\n",
    "col2 = [f\"Day_{i}\" for i in range(1, n + 1)]\n",
    "row2 = [f\"Time_{i}\" for i in range(1, n + 1)]\n",
    "for r in range(n):\n",
    "    for c in range(n):\n",
    "        if np.random.random() < 0.25:\n",
    "            data2[r, c] = np.nan\n",
    "data_frame_fillna = pd.DataFrame(data2, row2, col2)\n",
    "data_frame_fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:48.971930Z",
     "start_time": "2020-09-30T11:32:48.946988Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_fillna.fillna(value=\"VALOR ERRADO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:51.825059Z",
     "start_time": "2020-09-30T11:32:51.739049Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Caso queiramos preencher o valor faltante pelo valor anterior podemos realizar isso aplicando o `method=\"ffill\"`\n",
    "# Criando data frame com valores nan\n",
    "np.random.seed(100)\n",
    "n = 1440 # Equivalente a coleta de pontos cada 60 segundos por 24 h\n",
    "r_n = 5\n",
    "data2 = np.random.randint(27, 33, (n, r_n)).astype(object)\n",
    "col2 = [f\"Reactor_{i}\" for i in range(1, r_n + 1)]\n",
    "row2 = [f\"Time_{i}\" for i in range(1, n + 1)]\n",
    "for r in range(data2.shape[0]):\n",
    "    for c in range(data2.shape[1]):\n",
    "        if np.random.random() < 0.25:\n",
    "            data2[r, c] = np.nan\n",
    "data_frame_fillna = pd.DataFrame(data2, row2, col2)\n",
    "data_frame_fillna.info()\n",
    "data_frame_fillna.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:54.821668Z",
     "start_time": "2020-09-30T11:32:54.794244Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:57.157307Z",
     "start_time": "2020-09-30T11:32:57.149013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_fillna.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:32:58.842543Z",
     "start_time": "2020-09-30T11:32:58.807855Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:00.963389Z",
     "start_time": "2020-09-30T11:33:00.912584Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_frame_fillna.info()\n",
    "data_frame_fillna.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### replace\n",
    "Uma das alternativas mais adequadas para trabalhar com valores ausentes ou inadequados é utilizando a função [`replace`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html). Esta função trabalha de forma semelhante a `dropna` e `filna` porém agora podemos indicar qual ou quais valores queremos substituir. A sintaxe para o funcionamento deste método é:\n",
    "\n",
    "```python\n",
    "DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:10.520892Z",
     "start_time": "2020-09-30T11:33:10.468955Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vamos contiuar com data_frame_nan\n",
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:12.459536Z",
     "start_time": "2020-09-30T11:33:12.447842Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Observemos que temos varios valores Nan\n",
    "data_frame_nan.replace(to_replace=np.nan, value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:14.079247Z",
     "start_time": "2020-09-30T11:33:14.063966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Podemos passar uma lista de valores para ser subtituido\n",
    "data_frame_nan.replace(to_replace=[np.nan, 8], value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:15.732971Z",
     "start_time": "2020-09-30T11:33:15.717231Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# E também uma lista de valores para substuir\n",
    "data_frame_nan.replace(to_replace=[np.nan, 8], value=[100, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:18.488237Z",
     "start_time": "2020-09-30T11:33:18.429187Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Voltando ao exemplo do sensor de temperatura\n",
    "np.random.seed(100)\n",
    "n = 1440 # Equivalente a coleta de pontos cada 60 segundos por 24 h\n",
    "r_n = 3\n",
    "err = [10, 15, 20, 40, 35]\n",
    "data2 = np.random.uniform(27, 33, (n, r_n)).astype(object)\n",
    "col2 = [f\"Reactor_{i}\" for i in range(1, r_n + 1)]\n",
    "row2 = [f\"Time_{i}\" for i in range(1, n + 1)]\n",
    "for r in range(data2.shape[0]):\n",
    "    for c in range(data2.shape[1]):\n",
    "        if np.random.random() < 0.25:\n",
    "            data2[r, c] = np.nan\n",
    "        elif np.random.random() < 0.1:\n",
    "            data2[r, c] = np.random.choice(err)\n",
    "data_frame_replace = pd.DataFrame(data2, row2, col2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:20.859876Z",
     "start_time": "2020-09-30T11:33:20.839345Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_frame_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:23.474138Z",
     "start_time": "2020-09-30T11:33:22.927536Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib nbagg\n",
    "for react in data_frame_replace.columns:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(data_frame_replace[react].values,\n",
    "             ls=\"-\",\n",
    "             c='black',\n",
    "             marker=\"o\", \n",
    "             markersize=1.0,\n",
    "             markeredgecolor='blue',\n",
    "             lw=0.1)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Temperature [°C]\")\n",
    "    ax.set_title(react)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:32.166000Z",
     "start_time": "2020-09-30T11:33:32.096856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_replace.replace(to_replace=[40, 35, 20, 15, 10, np.nan], value=data_frame_replace.mean().mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T12:27:58.175489Z",
     "start_time": "2020-09-23T12:27:58.148180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Groupby, aggregate e apply\n",
    "Quando trabalhamos com dados qualitativos nominais pode ser necessário realizar agrupamentos e aplicar funções neste grupo de dados para conseguir entender melhor nosso sistema. Panda oferece uma serie de funções que ajudam a realizar isso. Cabe destacar que o potencial de Pandas está no uso em conjunto destas funções e outras.\n",
    "\n",
    "---\n",
    "\n",
    "A função [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) é umas das função **mais importantes** da biblioteca Pandas devido a que permite realizar o agrupamento de grande quantidade de dados e aplicar funções sobre esses valores agrupados de forma rápida. Para aplicar essa função utilizamos a seguinte sintaxe:\n",
    "```python\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=<object object>, observed=False, dropna=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "A função [`aggregate`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.aggregate.html) permite aplicar uma (ou mais funções) sobre uma(s) coluna(s) ou fila(s).\n",
    "\n",
    "**Observações**:\n",
    "- Podem ser aplicadas funções `built-in function`, `lambda functions` ou funções criadas por nós;\n",
    "- Podem ser aplicadas diferentes quantidades e tipos de funções para diferentes colunas ou filas do mesmo DataFrame;\n",
    "- Ao momento de passar a funções não é necessário realizar a chamada da função.\n",
    "\n",
    "A sintaxe utilizada para aplicar esta função é:\n",
    "```python\n",
    "DataFrame.aggregate(func=None, axis=0, *args, **kwargs)\n",
    "```\n",
    "***Recomendo ler a [documentação da função aggregate](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.aggregate.html) para conseguir entender melhor seu funcionamento***.\n",
    "\n",
    "---\n",
    "\n",
    "A função [`apply`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) permite aplicar **UMA FUNÇÃO** sobre uma Series ou um DataFrame, especificando ou eixo onde dever ser aplicada a função.\n",
    "\n",
    "**Observações**:\n",
    "- Podem ser aplicadas funções `built-in function`,  `lambda functions` ou funções criadas por nós;\n",
    "- Ao momento de passar a funções não é necessário realizar a chamada da função.\n",
    "\n",
    "A sintaxe para utilizar esta função é:\n",
    "\n",
    "```python\n",
    "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwds)\n",
    "```\n",
    "***Recomendo ler a [documentação da função apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) para conseguir entender melhor seu funcionamento***.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:43.004972Z",
     "start_time": "2020-09-30T11:33:42.911605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Para entender o funcionamento da função groupby vamos a criar uma matrix de dados\n",
    "n = 1500\n",
    "np.random.seed(100)\n",
    "empresas = [f\"Empresa {np.random.randint(1, 51)}\" for _ in range(n)]\n",
    "valor_investido = [np.random.uniform(500, 3500) for _ in range(n)]\n",
    "retorno = [np.random.uniform(2000, 5000) for _ in range(n)]\n",
    "transferencias = [np.random.randint(50, 150) for _ in range(n)]\n",
    "matriz = np.c_[valor_investido, retorno, transferencias]\n",
    "colum = \"Valor investido ($R), Retorno ($R), Transferencias\".split(\", \")\n",
    "#-----------------------------------------------------------------------\n",
    "# Criação do DataFrame\n",
    "data_frame_groupby = pd.DataFrame(data=matriz, columns=colum )\n",
    "data_frame_groupby[\"Lucro ($)\"] = data_frame_groupby[\"Retorno ($R)\"] - data_frame_groupby[\"Valor investido ($R)\"]\n",
    "data_frame_groupby[\"Empresas\"] = empresas\n",
    "data_frame_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:46.446270Z",
     "start_time": "2020-09-30T11:33:46.435661Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_groupby[\"Empresas\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T17:29:32.238627Z",
     "start_time": "2020-09-22T17:29:32.225624Z"
    },
    "hidden": true
   },
   "source": [
    "### Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:48.153816Z",
     "start_time": "2020-09-30T11:33:48.149868Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Para entender o conceito de Groupby, vamos agrupar os dados por empresas\n",
    "dfgroupby = data_frame_groupby.groupby(by=\"Empresas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:49.763497Z",
     "start_time": "2020-09-30T11:33:49.754675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Observemos que o retorno da função groupby é o endereço na memoria de um objeto\n",
    "dfgroupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:52.873953Z",
     "start_time": "2020-09-30T11:33:52.820905Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Para conseguir visualizar o DataFrame, devemos aplicar uma função sobre os valores\n",
    "dfgroupby.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:55.867233Z",
     "start_time": "2020-09-30T11:33:55.796399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Podemos utilizar o groupby para realizar agrupamento por camadas\n",
    "agrupamento_empr_trans = data_frame_groupby.groupby([\"Empresas\", \"Transferencias\"]).mean()\n",
    "agrupamento_empr_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:33:58.582424Z",
     "start_time": "2020-09-30T11:33:58.517632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agrupamento_trans_empr = data_frame_groupby.groupby([\"Transferencias\", \"Empresas\"]).mean()\n",
    "agrupamento_trans_empr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:00.802643Z",
     "start_time": "2020-09-30T11:34:00.773934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# E se queremos realizar filtragem ao momento de aplicar o filtro?\n",
    "agrupamento_empr_trans[(agrupamento_empr_trans[\"Valor investido ($R)\"]>1800) & \n",
    "                        (agrupamento_empr_trans[\"Lucro ($)\"]>1500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:02.409820Z",
     "start_time": "2020-09-30T11:34:02.392829Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Podemos utilizar algums metodos para potencializar o uso de groupby\n",
    "data_frame_groupby.groupby([\"Empresas\"]).get_group((\"Empresa 1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:05.219157Z",
     "start_time": "2020-09-30T11:34:05.176100Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_groupby.groupby([\"Empresas\", \"Transferencias\"]).get_group((\"Empresa 1\", 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:07.960660Z",
     "start_time": "2020-09-30T11:34:07.832792Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# podemos aplicar aggreagate para um groupby de dois niveis\n",
    "\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "dfgroupby.aggregate({\"Lucro ($)\": [min, max, np.mean, np.std],\n",
    "                     \"Retorno ($R)\": [min, max, np.mean, np.std],\n",
    "                     \"Transferencias\": [min, max]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:10.737072Z",
     "start_time": "2020-09-30T11:34:10.678012Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agrupamento_empr_trans.aggregate({\"Lucro ($)\": [min, max, np.mean, np.std],\n",
    "                     \"Retorno ($R)\": [min, max, np.mean, np.std]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:12.294201Z",
     "start_time": "2020-09-30T11:34:12.265217Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exemplo com dados de lingaugems de programação\n",
    "pd.set_option('display.max_rows', 80)\n",
    "df_ling = pd.read_csv(\"./Dados/programming_languages.csv\")\n",
    "df_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:15.792410Z",
     "start_time": "2020-09-30T11:34:15.782383Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_lig_grop = df_ling.groupby(by=\"year\")\n",
    "df_lig_grop[\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:17.771961Z",
     "start_time": "2020-09-30T11:34:17.760585Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Obtendo um dataframe com as linguagens criadas em cada\n",
    "pd.set_option('display.max_rows', 50)\n",
    "df_lig_grop[\"language\"].apply(','.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:20.799670Z",
     "start_time": "2020-09-30T11:34:20.780525Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Obtendo um dataframe com as linguagens criadas em cada\n",
    "df_lig_grop[\"language\"].apply(len).values\n",
    "df_lig_grop[\"language\"].apply(len).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:34:22.632045Z",
     "start_time": "2020-09-30T11:34:22.540089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df_lig_grop[\"language\"].apply(len).index.values,\n",
    "         df_lig_grop[\"language\"].apply(len).values,\n",
    "        ls=\"\",\n",
    "        marker=\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Juntando DataFrames\n",
    "Em algumas ocasiones pode ser necessário criar um DataFrame utilizando dois ou mais DataFrame já existentes. Panda facilita realizar estas operações utilizando as funções `concat`, `merge` e `join`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Concat\n",
    "A função [`concat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) permite realizar a união de dois DataFrame. A união pode ser feita adicionando o DataFrame como uma série de colunas ou filas novas. Para aplicar está funções se aplica a seguinte sintaxe:\n",
    "\n",
    "```python\n",
    "pandas.concat(objs: Union[Iterable[FrameOrSeries], Mapping[Label, FrameOrSeries]], axis='0', join: str = \"'outer'\", ignore_index: bool = 'False', keys='None', levels='None', names='None', verify_integrity: bool = 'False', sort: bool = 'False', copy: bool = 'True')\n",
    "```\n",
    "Cabe destacar que esse método é próprio das `series` e dos `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:36.796413Z",
     "start_time": "2020-09-30T11:35:36.784783Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = np.arange(1, 10).reshape((3, 3))\n",
    "columnas = [f\"Col {i}\" for i in range(1, 4)]\n",
    "data_frame_1 = pd.DataFrame(data=data, columns=columnas)\n",
    "data_frame_2 = pd.DataFrame(data=data, columns=columnas)*10\n",
    "data_frame_3 = pd.DataFrame(data=data, columns=columnas)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:39.529363Z",
     "start_time": "2020-09-30T11:35:39.519617Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:41.364687Z",
     "start_time": "2020-09-30T11:35:41.339769Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:43.292239Z",
     "start_time": "2020-09-30T11:35:43.276880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:50.946098Z",
     "start_time": "2020-09-30T11:35:50.937653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Passando os DataFrame que queremos juntar\n",
    "pd.concat([data_frame_1, data_frame_2, data_frame_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:35:53.556857Z",
     "start_time": "2020-09-30T11:35:53.531787Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# observemos que os índices foram mantidos para os DataFrame original\n",
    "# Se queremos “reiniciar” os índices passamos o argumento\n",
    "pd.concat([data_frame_1, data_frame_2, data_frame_3], ignore_index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:36:11.954036Z",
     "start_time": "2020-09-30T11:36:11.921436Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Como vimos na reunião passada podemos passar o argumento axis para definir sobre qual eixo queremos realizar a operação\n",
    "pd.concat([data_frame_1, data_frame_2, data_frame_3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:36:32.357917Z",
     "start_time": "2020-09-30T11:36:32.344979Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([data_frame_1, data_frame_2, data_frame_3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:36:37.286410Z",
     "start_time": "2020-09-30T11:36:37.248518Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# O que acontece quando os index dos DataFrame são diferentes?\n",
    "data_frame_2.index = pd.RangeIndex(start=3, stop=6, step=1)\n",
    "data_frame_3.index = pd.RangeIndex(start=6, stop=9, step=1)\n",
    "pd.concat([data_frame_1, data_frame_2, data_frame_3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### merge\n",
    "Pode ser necessário realizar a união de duas tabelas que compartem os elementos de uma coluna, neste caso a função `concat` não é a mais indicada. Pandas possui o método [`marge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) que realiza a junção de duas tabelas mesclando os elementos que compartilham a mesma coluna. A sintaxe para ralizar essa operação é:\n",
    "```python\n",
    "DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes='_x', '_y', copy=True, indicator=False, validate=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:37:19.758910Z",
     "start_time": "2020-09-30T11:37:19.741414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Modificando os DataFrame\n",
    "data_frame_1[\"coluna em comum\"] = \"A B C\".split(\" \")\n",
    "data_frame_2[\"coluna em comum\"] = \"A C B\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:37:21.225479Z",
     "start_time": "2020-09-30T11:37:21.206416Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:37:22.921542Z",
     "start_time": "2020-09-30T11:37:22.909243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:37:24.444867Z",
     "start_time": "2020-09-30T11:37:24.406573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(data_frame_1, data_frame_2, on=\"coluna em comum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:37:37.704493Z",
     "start_time": "2020-09-30T11:37:37.693326Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Podemos passar mais de uma coluna em comum\n",
    "data_frame_1[\"coluna em comum 2\"] = \"X O I\".split(\" \")\n",
    "data_frame_2[\"coluna em comum 2\"] = \"Q I X\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:37:49.028910Z",
     "start_time": "2020-09-30T11:37:49.014986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:37:51.907260Z",
     "start_time": "2020-09-30T11:37:51.892282Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:39:28.118681Z",
     "start_time": "2020-09-30T11:39:28.097491Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(data_frame_1, data_frame_2, on=[\"coluna em comum\", \"coluna em comum 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:39:48.717685Z",
     "start_time": "2020-09-30T11:39:48.692149Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(data_frame_1, data_frame_2, on=[\"coluna em comum\", \"coluna em comum 2\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:40:11.152766Z",
     "start_time": "2020-09-30T11:40:11.132129Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(data_frame_1, data_frame_2, on=[\"coluna em comum\", \"coluna em comum 2\"], how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:40:13.486013Z",
     "start_time": "2020-09-30T11:40:13.456091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(data_frame_1, data_frame_2, on=[\"coluna em comum\", \"coluna em comum 2\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:40:15.610942Z",
     "start_time": "2020-09-30T11:40:15.591908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(data_frame_1, data_frame_2, on=[\"coluna em comum\", \"coluna em comum 2\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### join\n",
    "Pode ser necessário combinar DataFrames que possam compartilhar os mesmos índices, neste caso as funções `concat` e `merge` não são as mais adequadas. Para resolver esses problemas os DataFrame pandas possuem o método [`join`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html) o qual consegue juntar DataFrame avaliando as semelhanças entre os índices. A sintaxe utilizada é:\n",
    "```python\n",
    "DataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:40:35.835211Z",
     "start_time": "2020-09-30T11:40:35.828942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1.index = 1, 2, 3\n",
    "data_frame_2.index = 3, 1, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:40:37.800280Z",
     "start_time": "2020-09-30T11:40:37.790341Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:40:40.219098Z",
     "start_time": "2020-09-30T11:40:40.192282Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:40:48.492042Z",
     "start_time": "2020-09-30T11:40:48.457843Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1.join(data_frame_2, lsuffix=' Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Neste método temos o parâmetro how que modifica a forma de ralizar a união"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:41:29.622830Z",
     "start_time": "2020-09-30T11:41:29.551854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1.join(data_frame_2, lsuffix=' Original', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:41:32.381925Z",
     "start_time": "2020-09-30T11:41:32.364354Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1.join(data_frame_2, lsuffix=' Original', how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:41:34.079091Z",
     "start_time": "2020-09-30T11:41:34.037008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1.join(data_frame_2, lsuffix=' Original', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:41:36.428919Z",
     "start_time": "2020-09-30T11:41:36.405919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_1.join(data_frame_2, lsuffix=' Original', how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Operações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### unique\n",
    "\n",
    "O método [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html) mostra os valores únicos contidos numa `Series`. Esses valores são mostrados em ordem de ocorrência. A sintaxe para utilizar este método é:\n",
    "\n",
    "```python\n",
    "pandas.unique(values)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:41:55.732868Z",
     "start_time": "2020-09-30T11:41:55.724797Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Forma de ser usado 1\n",
    "data_frame_nan[\"Col_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:42:29.609617Z",
     "start_time": "2020-09-30T11:42:29.588693Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:42:45.820290Z",
     "start_time": "2020-09-30T11:42:45.811684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Forma de ser usado 2\n",
    "pd.unique(data_frame_nan[\"Col_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### nunique\n",
    "O método [`nunique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nunique.html) retorna o quantidades de ocorrências únicas numa `Series`. A sintaxe para utilizar esse método é:\n",
    "```python\n",
    "DataFrame.nunique(axis=0, dropna=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:42:57.678272Z",
     "start_time": "2020-09-30T11:42:57.643660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:43:06.042197Z",
     "start_time": "2020-09-30T11:43:06.031955Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Utilizando função sem passar nenhum tipo de parâmetro\n",
    "data_frame_nan.nunique()\n",
    "# Observemos que os valores Nan não são considerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:43:10.369467Z",
     "start_time": "2020-09-30T11:43:10.351067Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Utilizando utilizando o parâmetro dropna\n",
    "data_frame_nan.nunique(dropna=False)\n",
    "# Observemos que os valores Nan são considerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T14:33:40.514487Z",
     "start_time": "2020-09-28T14:33:40.505179Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Utilizando utilizando o parâmetro axis\n",
    "data_frame_nan.nunique(axis=1, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### value_counts\n",
    "A função [`value_counts`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) retorna uma `Series` com todos os valores e o número de ocorrências de cada valor. A sintaxe para utilizar essa função é\n",
    "```python\n",
    "Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:43:36.937094Z",
     "start_time": "2020-09-30T11:43:36.915438Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#  Utilizando a função com o parâmetro sort\n",
    "data_frame_nan[\"Col_1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:43:47.694888Z",
     "start_time": "2020-09-30T11:43:47.683021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Utilizando a função com o parâmetro sort e normalize\n",
    "data_frame_nan[\"Col_3\"].value_counts(sort=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T14:41:37.530007Z",
     "start_time": "2020-09-28T14:41:37.511852Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Utilizando a função com o parâmetro sort, normalize, dropna\n",
    "data_frame_nan[\"Col_3\"].value_counts(sort=True, normalize=False, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Utilizando a função com argumento sort nenhum tipo de parâmetro\n",
    "data_frame_nan[\"Col_3\"].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### del\n",
    "\n",
    "`del` não é uma função ou método próprio de Pandas. Porém podemos usar ele para eliminar colunas de forma rápida. A sintaxe para realizar isso é:\n",
    "```python\n",
    "del nome_DataFrame[‘Nome_da_coluna_a_ser_eliminada’]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:43:59.436768Z",
     "start_time": "2020-09-30T11:43:59.418371Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:02.315976Z",
     "start_time": "2020-09-30T11:44:02.312679Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del data_frame_nan[\"Col_6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:04.799740Z",
     "start_time": "2020-09-30T11:44:04.775664Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### columns\n",
    "O método `columns` retorna os labels do `DataFrame`. A sintaxe para utilizar este método é:\n",
    "```python\n",
    "DataFrame.columns\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:11.767886Z",
     "start_time": "2020-09-30T11:44:11.756342Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### index\n",
    "O método `index` retorna os índices (labels das filas) do `DataFrame`. A sintaxe para utilizar este método é:\n",
    "```python\n",
    "DataFrame.index\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:15.775251Z",
     "start_time": "2020-09-30T11:44:15.767225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### sort_values\n",
    "\n",
    "A função [`sort_values`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) organiza um DataFrame por colunas ou filas. Está função permite organizar os DataFrame por varias colunas ou filas ao mesmo tempo. A sintaxe para aplicar essa função é:\n",
    "```python\n",
    "DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:30.051718Z",
     "start_time": "2020-09-30T11:44:30.037348Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:36.573901Z",
     "start_time": "2020-09-30T11:44:36.529436Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Só utilizando o parâmetro by e ordenando somente por uma coluna\n",
    "data_frame_nan.sort_values(by=\"Col_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:48.451085Z",
     "start_time": "2020-09-30T11:44:48.425370Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Só utilizando o parâmetro by e ordenando somente por duas colunas\n",
    "data_frame_nan.sort_values(by=[\"Col_3\", \"Col_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:44:59.045829Z",
     "start_time": "2020-09-30T11:44:59.025410Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Organizando o vetor por filas\n",
    "data_frame_nan.sort_values(by=[\"Row_2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:45:05.220018Z",
     "start_time": "2020-09-30T11:45:05.200376Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Organizando o vetor por filas\n",
    "data_frame_nan.sort_values(by=[\"Row_2\", \"Row_3\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### pivot\n",
    "\n",
    "O método [`pivot`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html) é um dos métodos mais simples de Pandas, mas ao mesmo tempo, um dos mais usados e mais poderosos (mais um). Esse método está no mesmo nível que `groupby` e `aggregate`. Esse método se encarrega de reestruturar a um DataFrame. A sintaxe para aplicar esse método é:\n",
    "```python\n",
    "DataFrame.pivot(index=None, columns=None, values=None)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:45:39.583377Z",
     "start_time": "2020-09-30T11:45:38.619976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_url = 'http://bit.ly/2cLzoxH'\n",
    "data_frame_exemple = pd.read_csv(data_url)\n",
    "data_frame_exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:45:51.574292Z",
     "start_time": "2020-09-30T11:45:51.541405Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Re-estruturando o dataframe\n",
    "data_frame_exemple.pivot(index=\"country\", columns=\"year\", values=\"lifeExp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:45:54.026629Z",
     "start_time": "2020-09-30T11:45:53.991484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Re-estruturando o dataframe, trabalhando com dois index\n",
    "data_frame_exemple.pivot(index=[\"country\", \"continent\"], columns=\"year\", values=\"lifeExp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:45:56.172407Z",
     "start_time": "2020-09-30T11:45:56.049513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Re-estruturando o dataframe, trabalhando com dois index\n",
    "data_frame_exemple.pivot(index=[\"country\", \"continent\"], columns=\"year\", values=[\"lifeExp\", \"pop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### describe\n",
    "\n",
    "A função [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) apresenta as estatísticas de um DataFrame, sendo: média, desvio padrão, quartis, etc. A sintaxe para aplicar está função é:\n",
    "```python\n",
    "DataFrame.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:46:03.668264Z",
     "start_time": "2020-09-30T11:46:03.632831Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_exemple.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:46:06.267453Z",
     "start_time": "2020-09-30T11:46:06.237320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### info\n",
    "\n",
    "O método [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) apresenta um resumo do DataFrame. A sintaxe para aplicar esse método é:\n",
    "```python\n",
    "DataFrame.info(verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:46:11.673644Z",
     "start_time": "2020-09-30T11:46:11.657955Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_exemple.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:46:13.719201Z",
     "start_time": "2020-09-30T11:46:13.691621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_nan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exportando e importando dados\n",
    "\n",
    "Uma das habilidades mais relevantes de Pandas é a forma eficiente de escrever e transformar esses arquivos em DataFrame. A biblioteca pandas possui mais de 15 funções que realizam a leitura de arquivos e os transformam em `pandas.DataFrame`.\n",
    "\n",
    "---\n",
    "As funções que utilizaremos para leitura de arquivos são:\n",
    "- `pd.read_csv()`\n",
    "- `pd.read_excel()`\n",
    "- `pd.read_html()`\n",
    "- `pd.to_csv()`\n",
    "- `pd.to_excel()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T17:59:01.091269Z",
     "start_time": "2020-09-28T17:59:01.082136Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T18:11:20.921006Z",
     "start_time": "2020-09-28T18:11:20.906337Z"
    },
    "hidden": true
   },
   "source": [
    "A função [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) realiza a leitura de arquivos `.csv` ou `.txt` e os transforma em DataFrame. A sintaxe para utilizar está função é:\n",
    "```python\n",
    "pandas.read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)\n",
    "```\n",
    "Como podemos observar esta função possui diversos parâmetros, porém o único parâmetro obrigatório é `filepath_or_buffer`, os outros parâmetros estão definidos por padrão. Mas devemos ter cuidado com o parâmetro `sep` o qual pude ser diferente ao valor padrão \"`,`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:46:24.062715Z",
     "start_time": "2020-09-30T11:46:23.961946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lendo um arquivo csv com separador padrão\n",
    "arquivo_1 = pd.read_csv(\"./Dados/arquivo1.csv\")\n",
    "arquivo_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:48:11.772514Z",
     "start_time": "2020-09-30T11:48:11.655509Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lendo mais um arquivo csv\n",
    "arquivo_2 = pd.read_csv(\"./Dados/arquivo2.csv\")\n",
    "arquivo_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:48:27.523949Z",
     "start_time": "2020-09-30T11:48:27.505513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lendo mais um arquivo csv\n",
    "arquivo_3 = pd.read_csv(\"./Dados/arquivo3.csv\")\n",
    "arquivo_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### read_excel\n",
    "A função [`read_excel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) permite a leitura de arquivos tipo excel. Vale  destacar que a as extensões permitidas são: xls, xlsx, xlsm, xlsb, odf, ods. A sintaxe para a utilizar esta função é:\n",
    "```python\n",
    "pandas.read_excel(io, sheet_name=0, header=0, names=None, index_col=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skip_footer=0, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:48:42.654792Z",
     "start_time": "2020-09-30T11:48:42.584886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arquivo_4 = pd.read_excel(io=\"./Dados/arquivo4.xlsx\")\n",
    "arquivo_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:48:49.968067Z",
     "start_time": "2020-09-30T11:48:46.112120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arquivo_5 = pd.read_excel(io=\"./Dados/arquivo5.xlsx\")\n",
    "arquivo_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:50:45.414362Z",
     "start_time": "2020-09-30T11:50:45.323445Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# E se o arquivo tem mais de uma aba?\n",
    "arquivo_6 = pd.read_excel(io=\"./Dados/arquivo6.xlsx\")\n",
    "arquivo_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### read_html\n",
    "A função [`read_html`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html) permite realizar a leitura de uma tabela contida num site. Para utilizar está função aplicamos a seguinte sintaxe:\n",
    "```python\n",
    "pandas.read_html(io, match='.+', flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False, tupleize_cols=None, thousands=', ', encoding=None, decimal='.', converters=None, na_values=None, keep_default_na=True, displayed_only=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:51:19.173010Z",
     "start_time": "2020-09-30T11:51:17.938872Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tabela_html_1 = pd.read_html(\"http://www.ipeadata.gov.br/ExibeSerie.aspx?serid=32098&module=M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T11:51:24.460232Z",
     "start_time": "2020-09-30T11:51:22.454701Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tabela_html_2 = pd.read_html(\"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/banklist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:38:06.074050Z",
     "start_time": "2020-09-28T19:38:06.059690Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### to_csv\n",
    "A função [`to_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) permite exportar um DataFrame para um arquivo .csv. A sintaxe para utilizar esta função e:\n",
    "```python\n",
    "DataFrame.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', line_terminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:52:40.711824Z",
     "start_time": "2020-09-28T19:52:40.688261Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tabela_html_1[2].to_csv(\"html_to_csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### to_excel\n",
    "A função [`to_excel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html) permite exportar uma DataFrame para um arquivo .xlsx. A sintaxe para utilizar esta função e:\n",
    "```python\n",
    "DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:54:11.630267Z",
     "start_time": "2020-09-28T19:54:11.428834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tabela_html_2[0].to_excel(\"html_to_excel.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
